# Writers Factory - Complete Architecture
**Date**: 2025-11-13
**Vision**: Multi-Model Tournament System for Computational Storytelling

---

## ğŸ¯ Core Vision

A **model-agnostic narrative creation system** where:
1. Writers launch **tournaments** - same prompt to multiple LLMs
2. System orchestrates parallel generation across 10+ models
3. UX dashboard shows side-by-side comparisons
4. Writers hybridize, score, and select best outputs
5. Analytics track which models excel at which tasks
6. Entire system is **cloneable** for new projects

---

## ğŸ“ Revised Directory Structure

```
writers-factory/
â”‚
â”œâ”€â”€ factory/                              # ğŸ­ THE FACTORY SYSTEM
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                             # Core tournament engine
â”‚   â”‚   â”œâ”€â”€ orchestrator.py               # Tournament coordinator
â”‚   â”‚   â”œâ”€â”€ agent_registry.py             # LLM registry & loader
â”‚   â”‚   â”œâ”€â”€ prompt_engine.py              # Prompt templates & adaptation
â”‚   â”‚   â”œâ”€â”€ context_assembler.py          # Knowledge base integration
â”‚   â”‚   â”œâ”€â”€ result_handler.py             # Output collection & storage
â”‚   â”‚   â””â”€â”€ config/
â”‚   â”‚       â”œâ”€â”€ agents.yaml               # â­ Agent registry
â”‚   â”‚       â”œâ”€â”€ prompts/                  # Prompt templates library
â”‚   â”‚       â””â”€â”€ settings.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                           # LLM integrations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_agent.py                 # Abstract base class
â”‚   â”‚   â”œâ”€â”€ anthropic/
â”‚   â”‚   â”‚   â”œâ”€â”€ claude_opus.py
â”‚   â”‚   â”‚   â”œâ”€â”€ claude_sonnet_4_5.py
â”‚   â”‚   â”‚   â”œâ”€â”€ claude_sonnet_3_5.py
â”‚   â”‚   â”‚   â””â”€â”€ legacy/
â”‚   â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â”‚   â”œâ”€â”€ gpt4o.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gpt4_turbo.py
â”‚   â”‚   â”‚   â””â”€â”€ gpt35_turbo.py
â”‚   â”‚   â”œâ”€â”€ google/
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_2_flash.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_1_5_pro.py
â”‚   â”‚   â”‚   â””â”€â”€ gemini_ultra.py
â”‚   â”‚   â”œâ”€â”€ xai/
â”‚   â”‚   â”‚   â””â”€â”€ grok.py
â”‚   â”‚   â”œâ”€â”€ chinese/                      # Qwen, DeepSeek, etc.
â”‚   â”‚   â”‚   â”œâ”€â”€ deepseek.py
â”‚   â”‚   â”‚   â”œâ”€â”€ qwen.py
â”‚   â”‚   â”‚   â”œâ”€â”€ doubao.py
â”‚   â”‚   â”‚   â”œâ”€â”€ baichuan.py
â”‚   â”‚   â”‚   â””â”€â”€ kimi.py
â”‚   â”‚   â”œâ”€â”€ opensource/                   # Mistral, Llama, etc.
â”‚   â”‚   â”‚   â”œâ”€â”€ mistral.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llama3.py
â”‚   â”‚   â”‚   â””â”€â”€ falcon.py
â”‚   â”‚   â””â”€â”€ registry.yaml                 # Agent metadata
â”‚   â”‚
â”‚   â”œâ”€â”€ knowledge/                        # Knowledge base systems
â”‚   â”‚   â”œâ”€â”€ cognee/
â”‚   â”‚   â”‚   â”œâ”€â”€ .venv-cognee/
â”‚   â”‚   â”‚   â”œâ”€â”€ setup.py
â”‚   â”‚   â”‚   â”œâ”€â”€ query.py
â”‚   â”‚   â”‚   â””â”€â”€ sync.py
â”‚   â”‚   â”œâ”€â”€ gemini_file_search/
â”‚   â”‚   â”‚   â”œâ”€â”€ setup.py
â”‚   â”‚   â”‚   â”œâ”€â”€ query.py
â”‚   â”‚   â”‚   â””â”€â”€ sync.py
â”‚   â”‚   â”œâ”€â”€ notebooklm/
â”‚   â”‚   â”‚   â””â”€â”€ query.py
â”‚   â”‚   â””â”€â”€ router.py                     # Smart routing logic
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/                         # Post-generation tools
â”‚   â”‚   â”œâ”€â”€ voice_validator.py
â”‚   â”‚   â”œâ”€â”€ metaphor_analyzer.py
â”‚   â”‚   â”œâ”€â”€ scoring_engine.py
â”‚   â”‚   â”œâ”€â”€ hybridizer.py                 # AI-assisted hybridization
â”‚   â”‚   â””â”€â”€ analytics.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                               # UX Dashboard (Phase 2)
â”‚   â”‚   â”œâ”€â”€ web/                          # React-based web UI
â”‚   â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ cli/                          # Rich CLI interface
â”‚   â”‚   â”‚   â”œâ”€â”€ factory_cli.py            # Main CLI
â”‚   â”‚   â”‚   â”œâ”€â”€ tournament_ui.py          # Tournament TUI
â”‚   â”‚   â”‚   â””â”€â”€ results_viewer.py         # Results comparison
â”‚   â”‚   â””â”€â”€ api/                          # Backend API
â”‚   â”‚       â”œâ”€â”€ server.py
â”‚   â”‚       â””â”€â”€ routes/
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                          # Data persistence
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.sql
â”‚   â”‚   â”‚   â””â”€â”€ migrations/
â”‚   â”‚   â”œâ”€â”€ tournaments/                  # Tournament results
â”‚   â”‚   â””â”€â”€ analytics/                    # Usage analytics
â”‚   â”‚
â”‚   â”œâ”€â”€ skills/                           # Claude Code skills
â”‚   â”‚   â”œâ”€â”€ _ACTIVE -> ../../.claude/skills/
â”‚   â”‚   â””â”€â”€ development/
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/                          # Utility scripts
â”‚   â”‚   â”œâ”€â”€ setup/
â”‚   â”‚   â”‚   â”œâ”€â”€ install.sh
â”‚   â”‚   â”‚   â””â”€â”€ new_project.sh
â”‚   â”‚   â””â”€â”€ maintenance/
â”‚   â”‚
â”‚   â””â”€â”€ docs/                             # Factory documentation
â”‚       â”œâ”€â”€ SETUP.md
â”‚       â”œâ”€â”€ AGENTS.md                     # Adding new LLMs
â”‚       â”œâ”€â”€ TOURNAMENTS.md                # Running tournaments
â”‚       â”œâ”€â”€ PROMPTS.md                    # Prompt engineering
â”‚       â”œâ”€â”€ ANALYTICS.md                  # Understanding metrics
â”‚       â””â”€â”€ API_REFERENCE.md
â”‚
â”œâ”€â”€ project/                              # ğŸ“š PROJECT DATA
â”‚   â”‚
â”‚   â”œâ”€â”€ manuscript/                       # The actual writing
â”‚   â”‚   â”œâ”€â”€ volume-1/
â”‚   â”‚   â”œâ”€â”€ volume-2/
â”‚   â”‚   â””â”€â”€ volume-3/
â”‚   â”‚
â”‚   â”œâ”€â”€ reference/                        # Knowledge base
â”‚   â”‚   â”œâ”€â”€ characters/
â”‚   â”‚   â”œâ”€â”€ worldbuilding/
â”‚   â”‚   â”œâ”€â”€ voice-and-style/
â”‚   â”‚   â”œâ”€â”€ themes/
â”‚   â”‚   â””â”€â”€ story-structure/
â”‚   â”‚
â”‚   â”œâ”€â”€ tournaments/                      # ğŸ¯ Tournament results
â”‚   â”‚   â”œâ”€â”€ active/                       # Current tournaments
â”‚   â”‚   â”œâ”€â”€ completed/                    # Finished tournaments
â”‚   â”‚   â”‚   â”œâ”€â”€ tournament-001-scene-2.1.5/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prompt.md
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ context.json
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ claude-sonnet-4.5.md
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ gpt-4o.md
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ gemini-2-flash.md
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deepseek-v3.md
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qwen-max.md
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ scores.json
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ winner.md
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ notes.md
â”‚   â”‚   â”‚   â””â”€â”€ [more tournaments]/
â”‚   â”‚   â””â”€â”€ templates/                    # Tournament templates
â”‚   â”‚
â”‚   â”œâ”€â”€ output/                           # Generated content
â”‚   â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â””â”€â”€ production/
â”‚   â”‚
â”‚   â””â”€â”€ archive/                          # Historical materials
â”‚
â”œâ”€â”€ .claude/                              # Claude Code config
â”‚   â””â”€â”€ skills/
â”‚
â”œâ”€â”€ .cursor/                              # Cursor AI config
â”‚
â”œâ”€â”€ .factory/                             # Factory runtime data
â”‚   â”œâ”€â”€ cache/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ analytics.db                      # SQLite analytics DB
â”‚
â”œâ”€â”€ config/                               # Project-level config
â”‚   â”œâ”€â”€ credentials.json                  # API keys
â”‚   â””â”€â”€ factory_settings.yaml
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                             # Project overview
â””â”€â”€ FACTORY.md                            # Quick start guide
```

---

## ğŸ—ï¸ System Architecture

### 1. Agent Registry System

**`factory/core/config/agents.yaml`**:
```yaml
agents:
  claude-sonnet-4.5:
    provider: anthropic
    model: claude-sonnet-4-5-20250929
    enabled: true
    context_window: 200000
    cost_per_1k_input: 0.003
    cost_per_1k_output: 0.015
    strengths:
      - creative_narrative
      - character_voice
      - philosophical_depth
    handler: factory.agents.anthropic.claude_sonnet_4_5.ClaudeSonnet45

  gpt-4o:
    provider: openai
    model: gpt-4o-2024-11-20
    enabled: true
    context_window: 128000
    cost_per_1k_input: 0.0025
    cost_per_1k_output: 0.01
    strengths:
      - dialogue
      - polish
      - consistency
    handler: factory.agents.openai.gpt4o.GPT4o

  gemini-2-flash:
    provider: google
    model: gemini-2.0-flash-exp
    enabled: true
    context_window: 1000000
    cost_per_1k_input: 0.00
    cost_per_1k_output: 0.00
    strengths:
      - long_context
      - reasoning
      - cost_effective
    handler: factory.agents.google.gemini_2_flash.Gemini2Flash

  deepseek-v3:
    provider: deepseek
    model: deepseek-chat
    enabled: true
    context_window: 64000
    cost_per_1k_input: 0.00027
    cost_per_1k_output: 0.0011
    strengths:
      - cost_effective
      - speed
      - creative
    handler: factory.agents.chinese.deepseek.DeepSeekV3

  # ... more agents
```

**Dynamic Loading**:
```python
from factory.core.agent_registry import AgentRegistry

# Load all enabled agents
registry = AgentRegistry("factory/core/config/agents.yaml")
enabled_agents = registry.get_enabled_agents()

# Disable agent for this tournament
registry.set_enabled("gpt-3.5-turbo", False)

# Get agent by name
agent = registry.get_agent("claude-sonnet-4.5")
```

---

### 2. Tournament Orchestration

**Tournament Definition**:
```python
from factory.core.orchestrator import Tournament

tournament = Tournament(
    name="scene-2.1.5-blackjack",
    prompt_template="scene_generation_v2",
    agents=["claude-sonnet-4.5", "gpt-4o", "gemini-2-flash", "deepseek-v3"],
    context={
        "character": "Mickey Bardot",
        "scene_type": "blackjack_game",
        "phase": 2,
        "key_beats": ["quantum_bleed", "noni_observation"]
    },
    knowledge_sources=["characters/mickey", "worldbuilding/quantum"],
    max_tokens=2000,
    temperature=0.8
)

# Run tournament (parallel execution)
results = await tournament.run()

# Results include:
# - Raw outputs from each agent
# - Token usage & cost
# - Response times
# - Auto-scored metrics
```

**Parallel Execution**:
```python
# factory/core/orchestrator.py
async def run_tournament(self):
    """Execute tournament with parallel agent calls."""

    # Prepare context for each agent
    contexts = await self._prepare_contexts()

    # Launch all agents in parallel
    tasks = []
    for agent_name in self.agents:
        agent = self.registry.get_agent(agent_name)
        context = contexts[agent_name]
        tasks.append(agent.generate(self.prompt, context))

    # Wait for all to complete (with timeout)
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Handle results, errors, timeouts
    return self._process_results(results)
```

---

### 3. Prompt Engine & Context Assembly

**Prompt Templates** (`factory/core/config/prompts/`):
```
prompts/
â”œâ”€â”€ scene_generation/
â”‚   â”œâ”€â”€ basic.md
â”‚   â”œâ”€â”€ enhanced_voice.md
â”‚   â””â”€â”€ philosophical_heavy.md
â”œâ”€â”€ dialogue/
â”‚   â”œâ”€â”€ witty.md
â”‚   â””â”€â”€ tense.md
â””â”€â”€ enhancement/
    â””â”€â”€ polish_v2.md
```

**Context Assembler**:
```python
from factory.core.context_assembler import ContextAssembler

assembler = ContextAssembler(
    knowledge_systems=["cognee", "gemini_file_search", "notebooklm"]
)

# Smart routing based on query type
context = await assembler.gather(
    query="Tell me about Mickey's quantum abilities",
    max_tokens=10000,
    prefer_local=True  # Use Cognee if available
)

# Per-agent adaptation (trim for smaller windows)
adapted = assembler.adapt_for_agent(
    context=context,
    agent="gpt-3.5-turbo",  # 16k window
    reserve_for_output=2000
)
```

---

### 4. UX Dashboard Architecture

#### Phase 1: Rich CLI (Immediate)
```bash
# Launch tournament
./factory.py tournament create \
  --name "scene-2.1.5" \
  --agents "claude,gpt4o,gemini,deepseek" \
  --prompt "scene_generation_v2" \
  --context "characters/mickey,worldbuilding/quantum"

# Monitor live progress
./factory.py tournament watch scene-2.1.5

# Compare results (side-by-side TUI)
./factory.py results compare scene-2.1.5

# Score and annotate
./factory.py results score scene-2.1.5 \
  --winner "claude-sonnet-4.5" \
  --notes "Best metaphor discipline"

# View analytics
./factory.py analytics show --agent "claude-sonnet-4.5"
```

#### Phase 2: Web Dashboard (Future)
- React-based SPA
- Real-time tournament monitoring
- Drag-and-drop agent selection
- Side-by-side diff viewer
- Annotation and scoring UI
- Analytics dashboards
- Export to manuscript

---

### 5. Analytics & Feedback System

**Analytics Database** (`.factory/analytics.db`):
```sql
-- Tournaments
CREATE TABLE tournaments (
    id TEXT PRIMARY KEY,
    name TEXT,
    prompt_template TEXT,
    created_at TIMESTAMP,
    status TEXT
);

-- Results
CREATE TABLE results (
    id TEXT PRIMARY KEY,
    tournament_id TEXT,
    agent_name TEXT,
    output_text TEXT,
    tokens_input INTEGER,
    tokens_output INTEGER,
    cost REAL,
    response_time_ms INTEGER,
    created_at TIMESTAMP
);

-- Scores
CREATE TABLE scores (
    result_id TEXT,
    dimension TEXT,  -- voice, metaphor, structure, etc.
    score INTEGER,
    notes TEXT,
    scored_by TEXT,  -- human or auto
    scored_at TIMESTAMP
);

-- Winners
CREATE TABLE winners (
    tournament_id TEXT,
    result_id TEXT,
    reason TEXT,
    selected_at TIMESTAMP
);
```

**Analytics Queries**:
```python
# Which agent wins most often?
analytics.agent_win_rate("claude-sonnet-4.5")

# Which agent is most cost-effective?
analytics.cost_per_win()

# Which prompt template performs best?
analytics.template_success_rate("scene_generation_v2")

# Average response time by agent
analytics.agent_performance_metrics()
```

---

## ğŸš€ Implementation Phases

### Phase 1: Core Engine (Week 1-2)
- [x] Agent registry system *(already have 5 agents!)*
- [ ] Tournament orchestrator
- [ ] Parallel execution engine
- [ ] Result storage system
- [ ] Basic CLI interface

### Phase 2: Knowledge Integration (Week 2-3)
- [x] Cognee integration *(done!)*
- [x] Gemini File Search integration *(done!)*
- [x] NotebookLM integration *(done!)*
- [ ] Smart context routing
- [ ] Per-agent context adaptation

### Phase 3: Prompt System (Week 3)
- [ ] Prompt template library
- [ ] Per-agent prompt adaptation
- [ ] Template versioning
- [ ] Prompt analytics

### Phase 4: Analytics (Week 4)
- [ ] SQLite analytics database
- [ ] Cost tracking
- [ ] Performance metrics
- [ ] Win rate analytics
- [ ] Export reports

### Phase 5: Enhanced CLI (Week 4-5)
- [ ] Rich TUI with live updates
- [ ] Side-by-side comparison viewer
- [ ] Scoring and annotation interface
- [ ] Batch tournament support

### Phase 6: Web Dashboard (Week 6+)
- [ ] React frontend
- [ ] REST API backend
- [ ] Real-time WebSocket updates
- [ ] Advanced analytics UI
- [ ] Export to manuscript

---

## ğŸ“¦ Cloning for New Projects

### New Project Setup:
```bash
# 1. Clone repository
git clone <repo> new-novel-project
cd new-novel-project

# 2. Run new project script
./factory/scripts/setup/new_project.sh "My New Novel"

# This:
# - Wipes project/ directory
# - Creates fresh manuscript/reference structure
# - Resets analytics database
# - Keeps factory/ intact
# - Updates README with new project name

# 3. Configure project
./factory.py init
# Prompts for:
#   - Project name
#   - Genre
#   - Key characters
#   - Worldbuilding elements
#   - Voice/style preferences

# 4. Add API keys
cp config/credentials.example.json config/credentials.json
# Edit with your keys

# 5. Ready to write!
./factory.py tournament create --name "opening-scene"
```

---

## ğŸ’¡ Key Features

### 1. Model Agnostic
- Add/remove LLMs via config, not code
- Support 10+ providers out of box
- Easy to add new models

### 2. Tournament-First
- Compare multiple models simultaneously
- Objective scoring and analytics
- Learn which models excel at which tasks

### 3. Knowledge-Aware
- Three knowledge systems integrated
- Smart routing based on query type
- Automatic context adaptation

### 4. Cost Conscious
- Track costs per tournament
- Cost-per-win analytics
- Mix expensive + cheap models strategically

### 5. Reproducible
- Every tournament logged
- Full prompt/context/result storage
- Can replay any tournament

### 6. Extensible
- Plugin architecture for new agents
- Custom scoring dimensions
- Custom prompt templates

---

## ğŸ¯ Success Metrics

After Phase 1 completion:
- âœ… Can run 5-model tournament in < 2 minutes
- âœ… All results stored with full metadata
- âœ… CLI provides clear winner recommendation
- âœ… Analytics track costs and performance

After Phase 5 completion:
- âœ… Can manage 10+ concurrent tournaments
- âœ… Rich TUI shows live progress
- âœ… Side-by-side comparison of results
- âœ… Export winning scenes to manuscript

After Phase 6 completion:
- âœ… Web dashboard for non-technical users
- âœ… One-click tournament launch
- âœ… Visual analytics and insights
- âœ… Production-ready for other writers

---

## ğŸ’­ Next Steps

Ready to build this? Here's my recommended order:

1. **Tonight/Tomorrow**: Reorganize repo with this structure
2. **This Week**: Build Phase 1 (Core Engine + CLI)
3. **Next Week**: Integrate existing tools into tournament system
4. **Week 3**: Polish and test with Explants Volume 2
5. **Week 4+**: Enhanced features and web dashboard

Sound good?
